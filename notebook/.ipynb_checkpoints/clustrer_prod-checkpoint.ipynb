{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from copy import copy, deepcopy\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CLUSTER_SIZE = 10\n",
    "# To calculate radius for each bubble\n",
    "MIN_RADIUS = 1\n",
    "MIN_ALLOWED_DISTANCE = 1\n",
    "\n",
    "\n",
    "def run_tsne(x):\n",
    "    \"\"\"\n",
    "    Reduce the dimension of the input vector\n",
    "\n",
    "    Arg:\n",
    "        x (numpy.array): a list of lists containing vectors.\n",
    "\n",
    "    Retrun:\n",
    "        (numpy.array): reduced dimension\n",
    "    \"\"\"\n",
    "    low_dim_x = TSNE(\n",
    "        n_components=2,\n",
    "        learning_rate=200,\n",
    "        perplexity=30\n",
    "    ).fit_transform(x)\n",
    "    return low_dim_x\n",
    "\n",
    "\n",
    "def reduce_dimension(embedding_data):\n",
    "    \"\"\"\n",
    "    Extracts the hight dimension vectors from the data,\n",
    "    run the dimension reducsion algorithm and add the\n",
    "    low dimension vectors to the original data\n",
    "\n",
    "    Arg:\n",
    "        embedding_data (List): A list of dictionaries where each\n",
    "                                dict element has a value for\n",
    "                                the key `embedding`.\n",
    "    \"\"\"\n",
    "    # get vectors\n",
    "    embedding_data = copy(embedding_data)\n",
    "    vect_list = []\n",
    "    for e in embedding_data:\n",
    "        vect_list.append(e.get('embedding'))\n",
    "\n",
    "    # reduce dimension\n",
    "    vect_array = np.array(vect_list)\n",
    "    low_dim_embeddings = run_tsne(vect_array)\n",
    "\n",
    "    # Merge back the low dimensions into the original data\n",
    "    for i, item in enumerate(embedding_data):\n",
    "        item['low_dim_embedding'] = list(low_dim_embeddings[i])\n",
    "    return embedding_data\n",
    "\n",
    "\n",
    "def ap_cluster(x):\n",
    "    \"\"\"\n",
    "    Clusters data using affinity propagation algorithm.\n",
    "    \"\"\"\n",
    "    clustering = AffinityPropagation(\n",
    "        random_state=5, damping=0.95\n",
    "    ).fit(x)\n",
    "\n",
    "    cluster_labels = clustering.labels_\n",
    "    cluster_centers = clustering.cluster_centers_\n",
    "    return cluster_labels, cluster_centers\n",
    "\n",
    "\n",
    "def cluster_data(data, coordinates_key=None):\n",
    "    \"\"\"\n",
    "    cluster a list of objects with a 'coordinates' key\n",
    "\n",
    "    Args\n",
    "        coordinates_key : string, A name for the lookup key for the coordinates\n",
    "        data : list[dicts], A list of objects that has a key for coordinates\n",
    "        [\n",
    "            {\n",
    "                coordinates_key: [x1, x2, ...],\n",
    "                ...\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "\n",
    "    Returns\n",
    "        Adds the clustering_info to each object in the input list of data\n",
    "    \"\"\"\n",
    "    # Cluster data\n",
    "    coordinates = []\n",
    "    for item in data:\n",
    "        coordinates.append(item[coordinates_key])\n",
    "    cluster_labels, cluster_centers = ap_cluster(np.array(coordinates))\n",
    "\n",
    "    # add clustering info to the data structure\n",
    "    for i, item in enumerate(data):\n",
    "        cluster_info = {}\n",
    "        cluster_info['is_cluster_head'] = item[coordinates_key] in cluster_centers\n",
    "        cluster_info['cluster_label'] = cluster_labels[i]\n",
    "        item['cluster_info'] = cluster_info\n",
    "        # TODO: remove this lines\n",
    "        # item['embedding'] = ''\n",
    "        # item['text'] = ''\n",
    "\n",
    "    # sort data\n",
    "    result = sorted(\n",
    "        data, key=lambda x:\n",
    "            (x['cluster_info']['cluster_label'], not x['cluster_info']['is_cluster_head'])\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def format_to_nested_clustering(clustered_data):\n",
    "    \"\"\"\n",
    "    transform a list of object into a nested list based on clustering info.\n",
    "    If there is only one cluster, it retruns the same input\n",
    "\n",
    "    Arg:\n",
    "        clustered_data (list): A flat list of objects\n",
    "\n",
    "    Return:\n",
    "        (list): a hierarchical list of objects\n",
    "    \"\"\"\n",
    "    # check the number of cluster heads; return if there is only one cluster\n",
    "    num_cluster_heads = 0\n",
    "    for item in clustered_data:\n",
    "        if item['cluster_info']['is_cluster_head']:\n",
    "            num_cluster_heads += 1\n",
    "    if num_cluster_heads == 1:\n",
    "        return clustered_data\n",
    "\n",
    "    # Break down if there are more than one cluster\n",
    "    result = []\n",
    "    for item in clustered_data:\n",
    "        item['children'] = item.get('children', [])\n",
    "        if item['cluster_info']['is_cluster_head']:\n",
    "            # Add cluster head to the tree and also add it as the first child\n",
    "            result.append(item)\n",
    "            if not item.get('children'):\n",
    "                result[-1]['children'].append(deepcopy(item))\n",
    "        else:\n",
    "            result[-1]['children'].append(item)\n",
    "    # Prune nodes with only one child.\n",
    "    # which would be the parent that is just repeated\n",
    "    for item in result:\n",
    "        if len(item['children']) == 1:\n",
    "            item['children'] = []\n",
    "    return result\n",
    "\n",
    "\n",
    "def cluster_hierarchically(\n",
    "    embedding_data_w_low_dim,\n",
    "    include_original_cluster_label=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Gets an array of input data with dimension and performs\n",
    "    clustering on them and represents data as hierarchical\n",
    "\n",
    "    This function can be called recursively\n",
    "\n",
    "    Args\n",
    "        [ {'low_dim_embedding': [], ...}, ...]\n",
    "    \"\"\"\n",
    "    embedding_data_w_low_dim = deepcopy(embedding_data_w_low_dim)\n",
    "\n",
    "    clustered_data = cluster_data(\n",
    "        embedding_data_w_low_dim,\n",
    "        coordinates_key='low_dim_embedding'\n",
    "    )\n",
    "    if include_original_cluster_label:\n",
    "        for item in clustered_data:\n",
    "            item['original_cluster_label'] = item['cluster_info']['cluster_label']\n",
    "\n",
    "    nested_clusters = format_to_nested_clustering(clustered_data)\n",
    "    return nested_clusters\n",
    "\n",
    "\n",
    "def bfs_break_down(head, max_cluster_size=MAX_CLUSTER_SIZE):\n",
    "    \"\"\"\n",
    "    Traverse the nested clustering and break down if a node has too many\n",
    "    children\n",
    "\n",
    "    Arg:\n",
    "        head (dict): a dictionary with the following formatting\n",
    "                    {\n",
    "                        'children': [\n",
    "                            {\n",
    "                                'children': [...]\n",
    "                                'uuid': '934b0cfe-98c1-4a69-ba01-61565d7ab709',\n",
    "                                ...\n",
    "                            },\n",
    "                            ...\n",
    "                        ]\n",
    "                    }\n",
    "    \"\"\"\n",
    "    frontiers = [head]\n",
    "    while frontiers:\n",
    "        next = frontiers.pop(0)\n",
    "        if len(next['children']) > max_cluster_size:\n",
    "            next['children'] = cluster_hierarchically(next['children'])\n",
    "        frontiers.extend(next['children'])\n",
    "\n",
    "\n",
    "def insert_children_count(head):\n",
    "    \"\"\"\n",
    "    Add total number of children for each node recursively\n",
    "\n",
    "    Arg:\n",
    "        head (dict): a dictionary with the following formatting\n",
    "                    {\n",
    "                        'children': [\n",
    "                            {\n",
    "                                'children': [...]\n",
    "                                'uuid': '934b0cfe-98c1-4a69-ba01-61565d7ab709',\n",
    "                                ...\n",
    "                            },\n",
    "                            ...\n",
    "                        ]\n",
    "                    }\n",
    "    \"\"\"\n",
    "    if not head['children']:\n",
    "        head['children_count'] = 0\n",
    "        return 0\n",
    "    sum = 0\n",
    "    for node in head['children']:\n",
    "        sum += 1 + node.get(\n",
    "            'children_count', insert_children_count(node)\n",
    "        )\n",
    "    head['children_count'] = sum\n",
    "    return sum\n",
    "\n",
    "\n",
    "def insert_d3uuid(head):\n",
    "    \"\"\"\n",
    "    Traverse the tree of data and insert a unique identifier for\n",
    "    each node that will be used for d3 distinctions later\n",
    "    \"\"\"\n",
    "    if not head:\n",
    "        return\n",
    "    frontiers = [head]\n",
    "    while frontiers:\n",
    "        next = frontiers.pop(0)\n",
    "        next['d3uuid'] = str(uuid4())\n",
    "        frontiers.extend(next['children'])\n",
    "\n",
    "\n",
    "def insert_parents_info(head):\n",
    "    \"\"\"\n",
    "    Insert parents coordinates and radius in each child\n",
    "\n",
    "    Arg:\n",
    "        head (dict): a dictionary with the following formatting\n",
    "                    {\n",
    "                        'children': [\n",
    "                            {\n",
    "                                'children': [...]\n",
    "                                'uuid': '934b0cfe-98c1-4a69-ba01-61565d7ab709',\n",
    "                                ...\n",
    "                            },\n",
    "                            ...\n",
    "                        ]\n",
    "                    }\n",
    "    \"\"\"\n",
    "    if not head:\n",
    "        return\n",
    "    frontiers = [head]\n",
    "    while frontiers:\n",
    "        next = frontiers.pop(0)\n",
    "        for child in next.get('children', []):\n",
    "            child['parent'] = {\n",
    "                'low_dim_embedding': next.get('low_dim_embedding'),\n",
    "                'radius': next.get('radius'),\n",
    "                'd3uuid': next.get('d3uuid')\n",
    "            }\n",
    "        frontiers.extend(next['children'])\n",
    "    return\n",
    "\n",
    "\n",
    "def get_radius_multiplier(clustering_data):\n",
    "    \"\"\"\n",
    "    get the max multiplier that is used to inflate the bubble sizes\n",
    "    Args\n",
    "        clustering_data : list(dict) : a list of objects. Objects have a key\n",
    "                            for number of children\n",
    "    \"\"\"\n",
    "    multiplier = float(\"inf\")\n",
    "    if len(clustering_data) < 2:\n",
    "        multiplier = 0\n",
    "    for i in range(len(clustering_data)):\n",
    "        for j in range(i + 1, len(clustering_data)):\n",
    "            filled = max(\n",
    "                np.sqrt(clustering_data[i]['children_count']),\n",
    "                np.sqrt(clustering_data[j]['children_count'])\n",
    "            )\n",
    "            p1 = np.array([\n",
    "                float(clustering_data[i]['low_dim_embedding'][0]),\n",
    "                float(clustering_data[i]['low_dim_embedding'][1])\n",
    "            ])\n",
    "            p2 = np.array([\n",
    "                float(clustering_data[j]['low_dim_embedding'][0]),\n",
    "                float(clustering_data[j]['low_dim_embedding'][1])\n",
    "            ])\n",
    "            d = np.linalg.norm(p1 - p2)\n",
    "            if d > MIN_ALLOWED_DISTANCE:\n",
    "                multiplier = min(multiplier, d / filled)\n",
    "    return multiplier\n",
    "\n",
    "\n",
    "def insert_radius(head, radius_multiplier_factor):\n",
    "    \"\"\"\n",
    "    Insert the radius in all object in the tree, and also for\n",
    "    each object, insert the radius of their parent\n",
    "\n",
    "    Arg:\n",
    "        head (dict): a dictionary with the following formatting\n",
    "                    {\n",
    "                        'children': [\n",
    "                            {\n",
    "                                'children': [...]\n",
    "                                'uuid': '934b0cfe-98c1-4a69-ba01-61565d7ab709',\n",
    "                                ...\n",
    "                            },\n",
    "                            ...\n",
    "                        ]\n",
    "                    }\n",
    "    \"\"\"\n",
    "    frontiers = copy(head['children'])\n",
    "    while frontiers:\n",
    "        next = frontiers.pop(0)\n",
    "        if next['children']:\n",
    "            next['radius'] = max([\n",
    "                np.sqrt(next['children_count']) * radius_multiplier_factor,\n",
    "                MIN_RADIUS\n",
    "            ])\n",
    "        else:\n",
    "            next['radius'] = MIN_RADIUS\n",
    "        frontiers.extend(next['children'])\n",
    "\n",
    "\n",
    "def insert_meta_data(head):\n",
    "    \"\"\"\n",
    "    Insert the metadat field that includes the following\n",
    "        metadata:\n",
    "            max_x, min_x\n",
    "            max_y, min_y\n",
    "    \"\"\"\n",
    "    min_x = float(\"inf\")\n",
    "    max_x = float(\"-inf\")\n",
    "    min_y = float(\"inf\")\n",
    "    max_y = float(\"-inf\")\n",
    "    frontiers = deepcopy(head['children'])\n",
    "    while frontiers:\n",
    "        next = frontiers.pop(0)\n",
    "        min_x = min(next['low_dim_embedding'][0] - next['radius'], min_x)\n",
    "        min_y = min(next['low_dim_embedding'][1] - next['radius'], min_y)\n",
    "        max_x = max(next['low_dim_embedding'][0] + next['radius'], max_x)\n",
    "        max_y = max(next['low_dim_embedding'][1] + next['radius'], max_y)\n",
    "        frontiers.extend(next['children'])\n",
    "    head['metadata'] = {\n",
    "        'x': {\n",
    "            'max': max_x,\n",
    "            'min': min_x,\n",
    "        },\n",
    "        'y': {\n",
    "            'max': max_y,\n",
    "            'min': min_y,\n",
    "        },\n",
    "        'radius': {\n",
    "            'max': max(max_x - min_x, max_y - min_y)\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def get_formatted_item(item):\n",
    "    \"\"\"\n",
    "    Arg:\n",
    "        An input item\n",
    "    \"\"\"\n",
    "    entry = {\n",
    "        'x': float(item['low_dim_embedding'][0]),\n",
    "        'y': float(item['low_dim_embedding'][1]),\n",
    "        'uuid': item.get('uuid'),\n",
    "        'd3uuid': item.get('d3uuid'),\n",
    "        'text': item.get('text'),\n",
    "        'cluster_label': int(item['original_cluster_label']),\n",
    "        'children_count': item['children_count'],\n",
    "        'radius': item['radius'],\n",
    "        'parent': {\n",
    "            'x': (\n",
    "                float(item['parent']['low_dim_embedding'][0])\n",
    "                if item['parent']['low_dim_embedding']\n",
    "                else float(item['low_dim_embedding'][0])\n",
    "            ),\n",
    "            'y': (\n",
    "                float(item['parent']['low_dim_embedding'][1])\n",
    "                if item['parent']['low_dim_embedding']\n",
    "                else float(item['low_dim_embedding'][1])\n",
    "                 ),\n",
    "            'radius': (\n",
    "                float(item['parent']['radius'])\n",
    "                if item['parent']['radius']\n",
    "                else item['radius']\n",
    "            ),\n",
    "            'd3uuid': item['parent']['d3uuid'],\n",
    "        }\n",
    "    }\n",
    "    return entry\n",
    "\n",
    "\n",
    "def get_formatted_data(node):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if not node:\n",
    "        return\n",
    "    new_node = {}\n",
    "    if 'low_dim_embedding' in node:\n",
    "        new_node = get_formatted_item(node)\n",
    "    new_node['children'] = [\n",
    "        get_formatted_data(c) for c in node['children']\n",
    "    ]\n",
    "    return new_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Load data from disk:\n",
    "\n",
    "file_name = 'output_1000.json'\n",
    "with open(file_name, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "\n",
    "embedding_data = [json.loads(line) for line in lines][:100]\n",
    "print(len(embedding_data))\n",
    "# embedding_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter().pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_low_dim = reduce_dimension(embedding_data)\n",
    "nested_clusters = cluster_hierarchically(data_w_low_dim, include_original_cluster_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = {}\n",
    "head['children'] = nested_clusters\n",
    "bfs_break_down(head)\n",
    "insert_children_count(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8228854531800918\n"
     ]
    }
   ],
   "source": [
    "insert_d3uuid(head)\n",
    "\n",
    "insert_parents_info(head)\n",
    "\n",
    "radius_multiplier_factor = get_radius_multiplier(head['children'])\n",
    "print(radius_multiplier_factor)\n",
    "insert_radius(head, radius_multiplier_factor)\n",
    "\n",
    "insert_meta_data(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = get_formatted_data(copy(head))\n",
    "formatted_data['metadata'] = head['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp(formatted_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
